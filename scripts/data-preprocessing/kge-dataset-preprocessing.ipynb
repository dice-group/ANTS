{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92531f40-6dbe-40ae-a59f-bd203d4d7e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"data/ESSUM/dbpedia/triples/train.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])\n",
    "val_df = pd.read_csv(\"data/ESSUM/dbpedia/triples/validation.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a59690f-accd-497f-b206-469b96da8983",
   "metadata": {},
   "source": [
    "## filtered URI only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb990ad6-d7ab-4410-a75d-f1d216cf00bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame has been saved to filtered_train.txt.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop rows where 'tail' has NaN values\n",
    "df = train_df.dropna(subset=['tail'])\n",
    "\n",
    "# Filter the DataFrame to exclude rows where 'tail' is a literal value\n",
    "df_filtered = df[df['tail'].str.startswith('http')]\n",
    "\n",
    "# Further filter to exclude rows where 'relation' contains 'homepage' or 'website'\n",
    "df_filtered = df_filtered[~df_filtered['relation'].str.contains('homepage|website', case=False)]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df_filtered.to_csv('filtered_train.txt', index=False, header=None, sep=\"\\t\")\n",
    "\n",
    "print(\"Filtered DataFrame has been saved to filtered_train.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317e1196-8b54-4a65-b279-75a96826ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame has been saved to filtered_dev.txt.\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'tail' has NaN values\n",
    "df = val_df.dropna(subset=['tail'])\n",
    "\n",
    "# Filter the DataFrame to exclude rows where 'tail' is a literal value\n",
    "df_filtered = df[df['tail'].str.startswith('http')]\n",
    "\n",
    "# Further filter to exclude rows where 'relation' contains 'homepage' or 'website'\n",
    "df_filtered = df_filtered[~df_filtered['relation'].str.contains('homepage|website', case=False)]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df_filtered.to_csv('filtered_dev.txt', index=False, header=None, sep=\"\\t\")\n",
    "\n",
    "print(\"Filtered DataFrame has been saved to filtered_dev.txt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea0810-f858-4f68-9f32-dad95ffa0f26",
   "metadata": {},
   "source": [
    "## Filtered all literal only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f22b1c8-aa2f-430e-bcb5-69862a3a10bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected DataFrame has been saved to filtered_all_literals_train\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop rows where 'tail' has NaN values\n",
    "df = train_df.dropna(subset=['tail'])\n",
    "\n",
    "# Filter the DataFrame to include rows where 'tail' does not start with 'http'\n",
    "literal_values_df = df[~df['tail'].str.startswith('http', na=False)]\n",
    "\n",
    "# Include rows where 'relation' contains 'homepage' or 'website'\n",
    "homepage_website_df = df[df['relation'].str.contains('homepage|website', case=False, na=False)]\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([literal_values_df, homepage_website_df]).drop_duplicates()\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv('filtered_all_literals_train.txt', index=False, header=None, sep=\"\\t\")\n",
    "\n",
    "print(\"Selected DataFrame has been saved to filtered_all_literals_train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d78fadc5-c65b-4045-b842-33080ca22747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected DataFrame has been saved to filtered_all_literals_val.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Drop rows where 'tail' has NaN values\n",
    "df = val_df.dropna(subset=['tail'])\n",
    "\n",
    "# Filter the DataFrame to include rows where 'tail' does not start with 'http'\n",
    "literal_values_df = df[~df['tail'].str.startswith('http', na=False)]\n",
    "\n",
    "# Include rows where 'relation' contains 'homepage' or 'website'\n",
    "homepage_website_df = df[df['relation'].str.contains('homepage|website', case=False, na=False)]\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([literal_values_df, homepage_website_df]).drop_duplicates()\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv('filtered_all_literals_val.txt', index=False, header=None, sep=\"\\t\")\n",
    "\n",
    "print(\"Selected DataFrame has been saved to filtered_all_literals_val.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb3a33-0f29-44bc-8d01-8aac1a35f850",
   "metadata": {},
   "source": [
    "## Selected numerical only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58aecde-a68a-4bbc-a5dd-36b3a1113aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame with numeric tails has been saved to numerical_literals.txt\n"
     ]
    }
   ],
   "source": [
    "literal_train_df = pd.read_csv(\"filtered_all_literals_train.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])\n",
    "literal_val_df = pd.read_csv(\"filtered_all_literals_val.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])\n",
    "df = pd.merge(literal_train_df, literal_val_df, how=\"outer\")\n",
    "\n",
    "# Convert the 'tail' column to numeric, coercing errors to NaN\n",
    "df['tail'] = pd.to_numeric(df['tail'], errors='coerce')\n",
    "\n",
    "# Filter the DataFrame to include only rows where 'tail' is numeric (not NaN)\n",
    "df_numeric_tails = df.dropna(subset=['tail'])\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df_numeric_tails.to_csv('numerical_literals,txt', index=False, header=None, sep=\"\\t\")\n",
    "\n",
    "print(\"Filtered DataFrame with numeric tails has been saved to numerical_literals.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e0af48-8537-4fd0-9e02-f7355b30f132",
   "metadata": {},
   "source": [
    "## Selected text literals only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55d54f94-27c4-4c0f-94d9-5dbc571acc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame with non-numeric tails has been saved to text_literals.txt.\n"
     ]
    }
   ],
   "source": [
    "literal_train_df = pd.read_csv(\"filtered_all_literals_train.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])\n",
    "literal_val_df = pd.read_csv(\"filtered_all_literals_val.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])\n",
    "df = pd.merge(literal_train_df, literal_val_df, how=\"outer\")\n",
    "\n",
    "# Ensure all values in the 'tail' column are strings\n",
    "df['tail'] = df['tail'].astype(str)\n",
    "\n",
    "# Filter out rows where 'tail' values are numeric using a regular expression\n",
    "df_non_numeric_tails = df[~df['tail'].str.match(r'^-?\\d+(\\.\\d+)?$', na=False)]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df_non_numeric_tails.to_csv('text_literals.txt', index=False, header=None, sep=\"\\t\")\n",
    "\n",
    "print(\"Filtered DataFrame with non-numeric tails has been saved to text_literals.txt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa3826-c1dd-417d-8983-42b002edf739",
   "metadata": {},
   "source": [
    "## Generate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e880cb93-4ea2-4a27-a7d4-885455006758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame has been saved to filtered_test.txt.\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"data/ESSUM/dbpedia/triples/test.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])\n",
    "# Drop rows where 'tail' has NaN values\n",
    "df = test_df.dropna(subset=['tail'])\n",
    "\n",
    "# Filter the DataFrame to exclude rows where 'tail' is a literal value\n",
    "df_filtered = df[df['tail'].str.startswith('http')]\n",
    "\n",
    "# Further filter to exclude rows where 'relation' contains 'homepage' or 'website'\n",
    "df_filtered = df_filtered[~df_filtered['relation'].str.contains('homepage|website', case=False)]\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "df_filtered.to_csv('filtered_test.txt', index=False, header=None, sep=\"\\t\")\n",
    "\n",
    "print(\"Filtered DataFrame has been saved to filtered_test.txt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297a230-b3a0-4f0b-8528-2e00c54623a8",
   "metadata": {},
   "source": [
    "## Generate entity types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32d4506f-2686-4ca3-a0d0-259bd9af7481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"essum-dataset-for-LiteralE/final/train.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])\n",
    "val_df = pd.read_csv(\"essum-dataset-for-LiteralE/final/valid.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\"])\n",
    "df = pd.merge(train_df, val_df, how=\"outer\")\n",
    "\n",
    "# Get unique entities and relations\n",
    "unique_heads = df['head'].unique().tolist()\n",
    "unique_tails = df['tail'].unique().tolist()\n",
    "unique_relations = df['relation'].unique().tolist()\n",
    "\n",
    "# Optionally, you can combine heads and tails to get a full list of unique entities\n",
    "all_entities = list(set(unique_heads + unique_tails))\n",
    "\n",
    "# Print the results\n",
    "#print(\"Unique Heads:\", unique_heads)\n",
    "#print(\"Unique Tails:\", unique_tails)\n",
    "#print(\"All Unique Entities:\", all_entities)\n",
    "#print(\"Unique Relations:\", unique_relations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7730a4-9d43-47e8-b5ad-0b8a5d3600e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity types have been saved to entity_types.json\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import json\n",
    "\n",
    "def extract_type_from_uri(uri):\n",
    "    if \"dbpedia.org/resource/Category:\" in uri:\n",
    "        return \"Category\"\n",
    "    elif \"dbpedia.org/ontology/\" in uri:\n",
    "        return uri.split('/')[-1]\n",
    "    elif \"dbpedia.org/resource/\" in uri:\n",
    "        if \"Person\" in uri.split('/')[-1]:\n",
    "            return \"Person\"\n",
    "        elif any(word in uri.lower() for word in [\"river\", \"mountain\", \"lake\"]):\n",
    "            return \"GeographicalFeature\"\n",
    "        elif any(word in uri.lower() for word in [\"university\", \"college\"]):\n",
    "            return \"EducationalInstitution\"\n",
    "    return None  # Return None if no type could be determined from the URI pattern\n",
    "\n",
    "def get_type_from_sparql(uri):\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "    query = f\"\"\"\n",
    "    SELECT DISTINCT ?type WHERE {{\n",
    "      <{uri}> a ?type .\n",
    "      FILTER(strstarts(str(?type), \"http://dbpedia.org/ontology/\"))\n",
    "    }}\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    types = [result['type']['value'].split('/')[-1] for result in results[\"results\"][\"bindings\"]]\n",
    "    return types if types else [\"Unknown\"]  # Return [\"Unknown\"] if no type was found\n",
    "\n",
    "def determine_entity_type(uri):\n",
    "    # First attempt to determine the type using URI patterns\n",
    "    type_from_uri = extract_type_from_uri(uri)\n",
    "    if type_from_uri is not None:\n",
    "        return type_from_uri\n",
    "    \n",
    "    # If the URI pattern method is inconclusive, query the SPARQL endpoint\n",
    "    types_from_sparql = get_type_from_sparql(uri)\n",
    "    return types_from_sparql[0] if types_from_sparql else \"Unknown\"\n",
    "\n",
    "# Determine types for each entity\n",
    "entity_types = {uri: determine_entity_type(uri) for uri in all_entities}\n",
    "\n",
    "# Save to JSON\n",
    "with open('entity_types.json', 'w') as f:\n",
    "    json.dump(entity_types, f, indent=4)\n",
    "\n",
    "print(\"Entity types have been saved to entity_types.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d6edd3-ad9d-4270-82d6-f63f61093512",
   "metadata": {},
   "source": [
    "## Generate range and domain constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b83699-dafd-4006-96fc-35d245237ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head: http://dbpedia.org/resource/173rd_Airborne_Brigade_Combat_Team Relation: http://dbpedia.org/ontology/battle Tail: http://dbpedia.org/resource/Operation_Hump\n",
      "Head: http://dbpedia.org/resource/1960_Glover_Trophy Relation: http://dbpedia.org/ontology/fastestDriver Tail: http://dbpedia.org/resource/Stirling_Moss\n",
      "Head: http://dbpedia.org/resource/1960_Glover_Trophy Relation: http://dbpedia.org/ontology/fastestDriverTeam Tail: http://dbpedia.org/resource/Cooper_Car_Company\n",
      "Head: http://dbpedia.org/resource/1960_Glover_Trophy Relation: http://dbpedia.org/ontology/firstDriver Tail: http://dbpedia.org/resource/Innes_Ireland\n",
      "Head: http://dbpedia.org/resource/1960_Glover_Trophy Relation: http://dbpedia.org/ontology/location Tail: http://dbpedia.org/resource/Goodwood_Circuit\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame rows to list of tuples (triples)\n",
    "triples_list = [tuple(x) for x in df.values]\n",
    "\n",
    "# Print the triples list\n",
    "for triple in triples_list[:5]:\n",
    "    head, rel, tail = triple\n",
    "    print('Head:', head, 'Relation:', rel, 'Tail:', tail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae451ca-0489-4af0-93c8-06cba85e0865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relation: battle, Domain: {'SportsTeam', 'Unknown', 'Person', 'Agent'}, Range: {'SocietalEvent'}\n",
      "Relation: fastestDriver, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: fastestDriverTeam, Domain: {'SocietalEvent'}, Range: {'Agent'}\n",
      "Relation: firstDriver, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: location, Domain: {'SocietalEvent', 'WrestlingEvent', 'Stadium', 'Infrastructure', 'Place'}, Range: {'Stadium', 'Person', 'Building', 'Infrastructure', 'ArchitecturalStructure', 'Place', 'Single'}\n",
      "Relation: secondDriver, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: secondTeam, Domain: {'SocietalEvent'}, Range: {'Company', 'Agent'}\n",
      "Relation: thirdDriver, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: thirdTeam, Domain: {'SocietalEvent'}, Range: {'Company', 'Agent'}\n",
      "Relation: subject, Domain: {'ChristianBishop', 'SocietalEvent', 'Animal', 'Mammal', 'SoccerTournament', 'EducationalInstitution', 'Fungus', 'Plant', 'Work', 'Person', 'Album', 'PeriodicalLiterature', 'Amphibian', 'WrestlingEvent', 'Athlete', 'Fish', 'Unknown', 'Place', 'Eukaryote', 'Agent', 'MilitaryConflict', 'Insect', 'Film', 'GeographicalFeature', 'Infrastructure', 'Fern', 'Reptile'}, Range: {'Category'}\n",
      "Relation: 22-rdf-syntax-ns#type, Domain: {'ChristianBishop', 'SocietalEvent', 'Animal', 'Mammal', 'Fern', 'EducationalInstitution', 'Fungus', 'Plant', 'Work', 'Person', 'Album', 'PeriodicalLiterature', 'Amphibian', 'WrestlingEvent', 'Athlete', 'Fish', 'Unknown', 'Place', 'Eukaryote', 'Agent', 'MilitaryConflict', 'Insect', 'Film', 'GeographicalFeature', 'Infrastructure', 'SoccerTournament', 'Reptile'}, Range: {'SocietalEvent', 'FootballMatch', 'Animal', 'Mammal', 'Congressman', 'BaseballPlayer', 'WrittenWork', 'EducationalInstitution', 'Olympics', 'RailwayStation', 'Species', 'Bird', 'Fungus', 'ScreenWriter', 'RouteOfTransportation', 'GrandPrix', 'BasketballPlayer', 'Cartoon', 'Writer', 'Tournament', 'Work', 'Plant', 'Wikidata:Q11424', 'Person', 'MilitaryPerson', 'SportsEvent', 'RadioStation', 'Royalty', 'ArchitecturalStructure', 'Organisation', 'Album', 'SoccerPlayer', 'PeriodicalLiterature', 'Amphibian', 'TennisTournament', 'Crustacean', 'AcademicJournal', 'Athlete', 'WrestlingEvent', 'Village', 'Fish', 'MusicalWork', 'Unknown', 'Place', 'Agent', 'Eukaryote', 'Settlement', 'MilitaryConflict', 'Politician', 'GolfPlayer', 'Event', 'Insect', 'Film', 'MusicalArtist', 'University', 'Newspaper', 'OlympicEvent', 'NaturalPlace', 'Reptile', 'Mountain', 'HistoricPlace', 'PopulatedPlace', 'Single', 'TelevisionShow', 'SoccerTournament', 'Location'}\n",
      "Relation: country, Domain: {'SocietalEvent', 'Work', 'Infrastructure', 'Place', 'EducationalInstitution', 'Film'}, Range: {'Country', 'Person', 'Place'}\n",
      "Relation: firstDriverTeam, Domain: {'SocietalEvent'}, Range: {'Agent'}\n",
      "Relation: poleDriver, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: depiction, Domain: {'SocietalEvent', 'Animal', 'Work', 'GeographicalFeature', 'Person', 'Infrastructure', 'Fish', 'PeriodicalLiterature', 'Place', 'MilitaryConflict', 'Insect', 'Reptile'}, Range: {'GeographicalFeature', 'Image', 'Unknown'}\n",
      "Relation: followingEvent, Domain: {'WrestlingEvent', 'SocietalEvent'}, Range: {'WrestlingEvent', 'SocietalEvent'}\n",
      "Relation: previousEvent, Domain: {'WrestlingEvent', 'SocietalEvent', 'SportsEvent'}, Range: {'WrestlingEvent', 'SocietalEvent'}\n",
      "Relation: rdf-schema#seeAlso, Domain: {'SportsTeamSeason', 'SocietalEvent', 'Place'}, Range: {'Unknown', 'SocietalEvent', 'Place'}\n",
      "Relation: city, Domain: {'EducationalInstitution', 'SocietalEvent', 'Place', 'School'}, Range: {'Place'}\n",
      "Relation: team, Domain: {'Athlete', 'Person', 'SocietalEvent'}, Range: {'EducationalInstitution', 'SportsTeam', 'SoccerClub', 'Agent'}\n",
      "Relation: category, Domain: {'SocietalEvent'}, Range: {'TelevisionShow'}\n",
      "Relation: championInDoubleMale, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: championInSingleMale, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: currentMember, Domain: {'Person', 'Unknown'}, Range: {'Person'}\n",
      "Relation: genre, Domain: {'Work', 'Person', 'Album'}, Range: {'Single', 'Genre', 'MusicGenre', 'Agent'}\n",
      "Relation: previousWork, Domain: {'Single', 'Work', 'Album'}, Range: {'Single', 'Work', 'Unknown', 'Album'}\n",
      "Relation: recordLabel, Domain: {'Work', 'Person', 'Album'}, Range: {'RecordLabel', 'Company'}\n",
      "Relation: subsequentWork, Domain: {'Single', 'Work', 'Album'}, Range: {'Work', 'Album'}\n",
      "Relation: broadcastArea, Domain: {'Agent'}, Range: {'Place'}\n",
      "Relation: programmeFormat, Domain: {'Agent'}, Range: {'Organisation'}\n",
      "Relation: birthPlace, Domain: {'ChristianBishop', 'MartialArtist', 'Person'}, Range: {'Person', 'PopulatedPlace', 'Unknown', 'Place', 'Settlement'}\n",
      "Relation: deathPlace, Domain: {'ChristianBishop', 'Person'}, Range: {'Place', 'Settlement'}\n",
      "Relation: party, Domain: {'Person'}, Range: {'Agent'}\n",
      "Relation: successor, Domain: {'Person'}, Range: {'Person'}\n",
      "Relation: thumbnail, Domain: {'SocietalEvent', 'Animal', 'Work', 'GeographicalFeature', 'Person', 'Infrastructure', 'Fish', 'PeriodicalLiterature', 'Place', 'MilitaryConflict', 'Insect', 'Fern', 'Reptile'}, Range: {'Image', 'Unknown'}\n",
      "Relation: artist, Domain: {'Work', 'Album'}, Range: {'Person', 'Agent'}\n",
      "Relation: college, Domain: {'Person'}, Range: {'EducationalInstitution', 'Organisation'}\n",
      "Relation: league, Domain: {'Person'}, Range: {'Agent'}\n",
      "Relation: termPeriod, Domain: {'Person'}, Range: {'TimePeriod'}\n",
      "Relation: class, Domain: {'Animal', 'Plant', 'Person', 'Fish', 'Unknown', 'Eukaryote', 'Amphibian', 'Insect', 'Fern', 'Reptile'}, Range: {'Animal', 'Plant', 'Unknown', 'Band'}\n",
      "Relation: family, Domain: {'Animal', 'Mammal', 'Plant', 'GeographicalFeature', 'Person', 'Fish', 'Unknown', 'Eukaryote', 'Amphibian', 'Insect'}, Range: {'Band', 'Plant', 'Animal', 'Unknown', 'Insect'}\n",
      "Relation: genus, Domain: {'Plant', 'Animal', 'GeographicalFeature', 'Person', 'Fish', 'Unknown', 'Eukaryote', 'Amphibian', 'Fern'}, Range: {'Animal', 'Plant', 'Person', 'Fish', 'Unknown', 'Amphibian', 'Insect'}\n",
      "Relation: order, Domain: {'Animal', 'Mammal', 'Plant', 'GeographicalFeature', 'Person', 'Fern', 'Fish', 'Unknown', 'Eukaryote', 'Amphibian', 'Insect', 'Fungus', 'Reptile'}, Range: {'Band', 'Mammal', 'Unknown', 'Eukaryote', 'Reptile'}\n",
      "Relation: phylum, Domain: {'Animal', 'Mammal', 'GeographicalFeature', 'Person', 'Fish', 'Eukaryote', 'Insect', 'Reptile'}, Range: {'Animal'}\n",
      "Relation: isPartOf, Domain: {'Place'}, Range: {'PopulatedPlace', 'Unknown', 'Place', 'Settlement'}\n",
      "Relation: timeZone, Domain: {'Place'}, Range: {'Settlement', 'Unknown', 'Galaxy', 'SportsEvent'}\n",
      "Relation: type, Domain: {'Album', 'Place'}, Range: {'MusicGenre', 'Unknown', 'Settlement'}\n",
      "Relation: binomialAuthority, Domain: {'Plant', 'Animal', 'GeographicalFeature', 'Fish', 'Unknown', 'Fungus', 'Reptile'}, Range: {'Person'}\n",
      "Relation: kingdom, Domain: {'Animal', 'Plant', 'GeographicalFeature', 'Fern', 'Fish', 'Unknown', 'Eukaryote', 'Amphibian', 'Fungus', 'Reptile'}, Range: {'Unknown'}\n",
      "Relation: parent, Domain: {'Person'}, Range: {'Person'}\n",
      "Relation: predecessor, Domain: {'Person'}, Range: {'Person'}\n",
      "Relation: division, Domain: {'Plant', 'Fungus', 'Unknown', 'Insect', 'Fern'}, Range: {'Animal', 'Plant', 'Unknown'}\n",
      "Relation: commander, Domain: {'MilitaryConflict', 'SocietalEvent'}, Range: {'Person', 'MilitaryPerson'}\n",
      "Relation: isPartOfMilitaryConflict, Domain: {'SocietalEvent'}, Range: {'MilitaryPerson', 'SocietalEvent'}\n",
      "Relation: place, Domain: {'MilitaryConflict', 'SocietalEvent'}, Range: {'City', 'Person', 'Place'}\n",
      "Relation: owl#differentFrom, Domain: {'SocietalEvent'}, Range: {'SocietalEvent'}\n",
      "Relation: associatedBand, Domain: {'Person', 'Agent'}, Range: {'Person'}\n",
      "Relation: associatedMusicalArtist, Domain: {'Person'}, Range: {'Person'}\n",
      "Relation: album, Domain: {'Work'}, Range: {'Work', 'Album'}\n",
      "Relation: format, Domain: {'Work', 'PeriodicalLiterature'}, Range: {'Software', 'RecordLabel', 'Unknown', 'University'}\n",
      "Relation: musicalArtist, Domain: {'Work'}, Range: {'Person', 'Agent', 'Band'}\n",
      "Relation: musicalBand, Domain: {'Work'}, Range: {'Person', 'Agent', 'Band'}\n",
      "Relation: producer, Domain: {'Work', 'GeographicalFeature', 'Album'}, Range: {'MusicalArtist', 'Person', 'Company', 'Agent'}\n",
      "Relation: writer, Domain: {'Work', 'GeographicalFeature'}, Range: {'Person', 'Agent'}\n",
      "Relation: position, Domain: {'Person'}, Range: {'Athlete', 'RugbyPlayer', 'BaseballPlayer'}\n",
      "Relation: language, Domain: {'Work', 'Person', 'Film'}, Range: {'Band', 'Language'}\n",
      "Relation: network, Domain: {'Work'}, Range: {'Company'}\n",
      "Relation: starring, Domain: {'Work', 'GeographicalFeature', 'Film'}, Range: {'Person'}\n",
      "Relation: species, Domain: {'Animal'}, Range: {'Person'}\n",
      "Relation: careerStation, Domain: {'Athlete', 'Person'}, Range: {'CareerStation'}\n",
      "Relation: basedOn, Domain: {'Work'}, Range: {'Person'}\n",
      "Relation: locatedInArea, Domain: {'GeographicalFeature', 'Place'}, Range: {'Person', 'Place'}\n",
      "Relation: mountainRange, Domain: {'GeographicalFeature', 'Place'}, Range: {'GeographicalFeature', 'Place'}\n",
      "Relation: parentMountainPeak, Domain: {'Place'}, Range: {'Place'}\n",
      "Relation: lastRace, Domain: {'Person'}, Range: {'SocietalEvent'}\n",
      "Relation: translator, Domain: {'Work'}, Range: {'Person'}\n",
      "Relation: ceremonialCounty, Domain: {'Place'}, Range: {'Place'}\n",
      "Relation: award, Domain: {'Person'}, Range: {'Unknown', 'Award'}\n",
      "Relation: influencedBy, Domain: {'Person'}, Range: {'Person'}\n",
      "Relation: nationality, Domain: {'Person'}, Range: {'Band'}\n",
      "Relation: notableWork, Domain: {'Person'}, Range: {'Work'}\n",
      "Relation: academicDiscipline, Domain: {'Person'}, Range: {'MedicalSpecialty'}\n",
      "Relation: publisher, Domain: {'Person', 'PeriodicalLiterature'}, Range: {'Company'}\n",
      "Relation: director, Domain: {'Work', 'Film'}, Range: {'Person'}\n",
      "Relation: musicComposer, Domain: {'Work', 'Film'}, Range: {'MusicalArtist', 'Person'}\n",
      "Relation: editing, Domain: {'GeographicalFeature'}, Range: {'Person'}\n",
      "Relation: district, Domain: {'Place'}, Range: {'Place'}\n",
      "Relation: instrument, Domain: {'Person'}, Range: {'Agent'}\n",
      "Relation: promotion, Domain: {'WrestlingEvent'}, Range: {'Company'}\n",
      "Relation: residence, Domain: {'Person'}, Range: {'Place'}\n",
      "Relation: governmentType, Domain: {'Place'}, Range: {'Unknown'}\n",
      "Relation: cinematography, Domain: {'Work'}, Range: {'Person'}\n",
      "Relation: distributor, Domain: {'Work'}, Range: {'Company'}\n",
      "Relation: almaMater, Domain: {'Person'}, Range: {'University', 'EducationalInstitution'}\n",
      "Relation: occupation, Domain: {'Person'}, Range: {'Person', 'Unknown', 'PersonFunction'}\n",
      "Relation: religion, Domain: {'Person'}, Range: {'Food'}\n",
      "Relation: stateOfOrigin, Domain: {'Person'}, Range: {'Band'}\n",
      "Relation: notableCommander, Domain: {'Agent'}, Range: {'Person'}\n",
      "Relation: headquarter, Domain: {'PeriodicalLiterature'}, Range: {'MusicalArtist', 'Person', 'Place'}\n",
      "Relation: department, Domain: {'Place'}, Range: {'Place'}\n",
      "Relation: region, Domain: {'Place'}, Range: {'AdministrativeRegion'}\n",
      "Relation: author, Domain: {'Work'}, Range: {'Person'}\n",
      "Relation: relative, Domain: {'Person'}, Range: {'Person'}\n",
      "Relation: series, Domain: {'Work'}, Range: {'Agent'}\n",
      "Relation: owner, Domain: {'PeriodicalLiterature'}, Range: {'Company'}\n",
      "Relation: bronzeMedalist, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: goldMedalist, Domain: {'SocietalEvent'}, Range: {'Person'}\n",
      "Relation: recordedIn, Domain: {'Album'}, Range: {'PopulatedPlace', 'Place'}\n",
      "Relation: operatedBy, Domain: {'Infrastructure'}, Range: {'Company'}\n",
      "Relation: servingRailwayLine, Domain: {'Infrastructure'}, Range: {'RailwayLine'}\n",
      "Domain and range dictionaries have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "domain_per_rel = defaultdict(set)\n",
    "range_per_rel = defaultdict(set)\n",
    "\n",
    "for head, rel, tail in triples_list:\n",
    "    head_type = entity_types.get(head, \"Unknown\")\n",
    "    tail_type = entity_types.get(tail, \"Unknown\")\n",
    "    \n",
    "    domain_per_rel[rel].add(head_type)\n",
    "    range_per_rel[rel].add(tail_type)\n",
    "\n",
    "# Example printout of domains and ranges\n",
    "for rel, domains in domain_per_rel.items():\n",
    "    print(f\"Relation: {rel.split('/')[-1]}, Domain: {domains}, Range: {range_per_rel[rel]}\")\n",
    "\n",
    "# Assuming domain_per_rel and range_per_rel are populated correctly\n",
    "# Convert defaultdict to a regular dictionary for JSON serialization\n",
    "domain_dict = {k: list(v) for k, v in domain_per_rel.items()}\n",
    "range_dict = {k: list(v) for k, v in range_per_rel.items()}\n",
    "\n",
    "# Save domain_per_rel to domain_per_rel.json\n",
    "with open('domain_per_rel.json', 'w') as f:\n",
    "    json.dump(domain_dict, f, indent=4)\n",
    "\n",
    "# Save range_per_rel to range_per_rel.json\n",
    "with open('range_per_rel.json', 'w') as f:\n",
    "    json.dump(range_dict, f, indent=4)\n",
    "\n",
    "print(\"Domain and range dictionaries have been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be97309-093f-4eec-9d67-384aaf01e19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
